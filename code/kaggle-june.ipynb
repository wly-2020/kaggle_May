{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport tensorflow as tf\nimport random\nimport os\n\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nSEED=40\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/sample_submission.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-06T02:50:20.535843Z","iopub.execute_input":"2021-06-06T02:50:20.536266Z","iopub.status.idle":"2021-06-06T02:50:29.454842Z","shell.execute_reply.started":"2021-06-06T02:50:20.536185Z","shell.execute_reply":"2021-06-06T02:50:29.453925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nlabel_map = {\n    'Class_1' : 0,\n    'Class_2' : 1,\n    'Class_3' : 2,\n    'Class_4' : 3,\n    'Class_5' : 4,\n    'Class_6' : 5,\n    'Class_7' : 6,\n    'Class_8' : 7,\n    'Class_9' : 8,\n}\ntrain['target'] = train['target'].map(label_map)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:50:29.456523Z","iopub.execute_input":"2021-06-06T02:50:29.456924Z","iopub.status.idle":"2021-06-06T02:50:29.638917Z","shell.execute_reply.started":"2021-06-06T02:50:29.456884Z","shell.execute_reply":"2021-06-06T02:50:29.637731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['feature_{}'.format(x) for x in range(75)]\nqt = train[features].quantile(np.arange(0,1,0.002))\ndef clip(df):\n    df = df.copy()\n    for feature in features:\n        df[feature] = df[feature].clip(lower=0, upper=qt.loc[0.998][feature])\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:50:29.64067Z","iopub.execute_input":"2021-06-06T02:50:29.640969Z","iopub.status.idle":"2021-06-06T02:50:30.325055Z","shell.execute_reply.started":"2021-06-06T02:50:29.640941Z","shell.execute_reply":"2021-06-06T02:50:30.324129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"values=[]\nlabels=[0,1,2,3,4,5,6,7,8,]\nfor feature in features:\n    grouped = clip(train).groupby(feature)\n    for value, group in grouped:\n        value=[feature, value]\n        for label in labels:\n            p =  (group['target'] == label).mean()\n            p = np.clip(p, 1e-06, 1 - 1e-06)\n            value.append(np.log(p+0.5))\n            value.append(np.log(p/(1-p)))\n        values.append(value)\ndf_proba = pd.DataFrame(values,\n                        columns=['feature', 'value',\n                                 'Class_1_proba1',\n                                 'Class_1_proba2',\n                                 'Class_2_proba1',\n                                 'Class_2_proba2',\n                                 'Class_3_proba1',\n                                 'Class_3_proba2',\n                                 'Class_4_proba1',\n                                 'Class_4_proba2',\n                                 'Class_5_proba1',\n                                 'Class_5_proba2',\n                                 'Class_6_proba1',\n                                 'Class_6_proba2',\n                                 'Class_7_proba1',\n                                 'Class_7_proba2',\n                                 'Class_8_proba1',\n                                 'Class_8_proba2',\n                                 'Class_9_proba1',\n                                 'Class_9_proba2',\n                                ])\nproba_dict_1={}\nproba_dict_2={}\n\nfor i in range(len(df_proba)):\n    feature = df_proba.iloc[i]['feature']\n    value = df_proba.iloc[i]['value']\n    proba_dict_1[feature, value] = df_proba.iloc[i][['Class_1_proba1','Class_2_proba1','Class_3_proba1','Class_4_proba1','Class_5_proba1','Class_6_proba1','Class_7_proba1','Class_8_proba1','Class_9_proba1',]].values.astype(float)\n    proba_dict_2[feature, value] = df_proba.iloc[i][['Class_1_proba2','Class_2_proba2','Class_3_proba2','Class_4_proba2','Class_5_proba2','Class_6_proba2','Class_7_proba2','Class_8_proba2','Class_9_proba2',]].values.astype(float)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:50:30.327168Z","iopub.execute_input":"2021-06-06T02:50:30.327606Z","iopub.status.idle":"2021-06-06T02:53:03.015672Z","shell.execute_reply.started":"2021-06-06T02:50:30.327563Z","shell.execute_reply":"2021-06-06T02:53:03.014376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.base import TransformerMixin\n\ndef reshape(df):\n    values=[]\n    for value in df.values:\n        values.append([_ for _ in value])\n    return np.array(values)\n\nclass MyTransformer1(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        for feature in features:\n            newX[feature] = X[feature].clip(lower=qt.loc[0.002][feature], upper=qt.loc[0.998][feature])\n            newX[feature] = 1 / (newX[feature] - newX[feature].min() + 1)\n        return newX\n\nclass MyTransformer2(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        X = clip(X)\n        for feature in features:\n            newX[feature] = X[feature].apply(lambda x:proba_dict_1[feature, x])\n        return reshape(newX).reshape((-1,75*9))\n\nclass MyTransformer3(MyTransformer2):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        X = clip(X)\n        for feature in features:\n            newX[feature] = X[feature].apply(lambda x:proba_dict_1[feature, x])\n        return reshape(newX)\n\ndef normalize(df, columns):\n    \"\"\"\n    sklearn.preprocessing.MinMaxScaler\n    \"\"\"\n    for column in columns:\n        min_val, max_val = df[column].agg([min,max])\n        df[column] = (df[column] - min_val) / (max_val - min_val)\n    return df\n\nclass MyTransformer4(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        for feature in features:\n            newX[feature] = X[feature].clip(lower=0).apply(lambda x:1/(x+1))\n        return normalize(newX, features)\n    \nclass MyTransformer5(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        for feature in features:\n            newX[feature] = X[feature].clip(lower=0).apply(lambda x:1/(x+1))\n        return normalize(newX, features)\n\nclass MyTransformer6(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        for feature in features:\n            newX[feature] = X[feature].clip(lower=qt.loc[0.002][feature], upper=qt.loc[0.998][feature])\n        return newX\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:53:03.017214Z","iopub.execute_input":"2021-06-06T02:53:03.017651Z","iopub.status.idle":"2021-06-06T02:53:03.03951Z","shell.execute_reply.started":"2021-06-06T02:53:03.017609Z","shell.execute_reply":"2021-06-06T02:53:03.038335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.base import ClassifierMixin\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n!pip install lightautoml\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML\nfrom lightautoml.tasks import Task\n\nfrom sklearn.pipeline import make_pipeline\nmy_model1 = CatBoostClassifier(\n    iterations=890,\n    min_child_samples=203,\n    eval_metric='MultiClass',\n    random_state=SEED,\n    max_depth=1,\n    verbose=1)\n\nmy_model2 = CatBoostClassifier(\n    iterations=160,\n    min_child_samples=30,\n    max_depth=3,\n    eval_metric='MultiClass',\n    random_state=SEED,\n    verbose=1)\n\ninitial_learning_rate = 0.001\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=10000,\n    decay_rate=0.96,\n    staircase=True)\noptimizer = tf.keras.optimizers.Adam(\n    learning_rate=lr_schedule, \n    beta_1=0.9,\n    beta_2=0.999,\n    epsilon=1e-07,\n    amsgrad=False,\n    name='Adam'\n)\nclass TensorflowClassifier(ClassifierMixin):\n    def __init__(self):\n        self.histories=[]\n        self.classes_ = [0,1,2,3,4,5,6,7,8]\n        self.model = tf.keras.Sequential([\n            tf.keras.layers.Flatten(input_shape=(75,9)),\n            tf.keras.layers.Dense(128, activation='relu'),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dense(32, activation='relu'),\n            tf.keras.layers.Dense(32, activation='relu'),\n            tf.keras.layers.Dense(32, activation='relu'),\n            tf.keras.layers.Dense(9, activation='softmax')\n        ])\n        self.model.compile(\n            optimizer=optimizer, \n            loss='sparse_categorical_crossentropy',\n            metrics=['sparse_categorical_crossentropy',])\n    def get_params(self,deep):\n        return {}\n    def fit(self, X, y):\n        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n        history = self.model.fit(X, y, epochs=300, batch_size = 75*9, validation_split=0.1, callbacks=[callback],verbose=0)\n        self.histories.append(history)\n        return self\n    def predict_proba(self, X):\n        return self.model.predict(X).reshape((-1, 9))\n\nmy_model3 = TensorflowClassifier()\n\nmy_model4 = LGBMClassifier(\n    random_state=SEED,\n    min_child_samples=150,\n    n_estimators=400,\n    max_depth = 3,\n    reg_alpha = 0.91,\n    min_child_weight = 0.001,\n)\n\nmy_model5 = GradientBoostingClassifier(\n    random_state=SEED,\n    min_samples_leaf=36,\n    n_estimators=100,\n    \n)\n\nclass AutoMLClassifier(ClassifierMixin):\n    def __init__(self):\n        task = Task('multiclass', metric = 'crossentropy', )\n        self.model  = TabularAutoML(\n            task = task,\n            timeout = 900,\n            general_params = {'nested_cv': False, 'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n            reader_params = {'cv': 20, 'random_state': SEED},\n            tuning_params = {'max_tuning_iter': 100, 'max_tuning_time': 100},\n            lgb_params = {'default_params': {'num_threads': 8}}, verbose=1)\n        self.classes_ = [0,1,2,3,4,5,6,7,8,]\n        self.train_prediction = None\n    def get_params(self,deep):\n        return {}\n    def dataframe(self, X):\n        if not isinstance(X, type(pd.DataFrame())):\n            X = pd.DataFrame(X, columns=['column_{}'.format(x) for x in range(X.shape[1])])\n        return X\n    def fit(self, X, y):\n        df = self.dataframe(X.copy())\n        df['target'] = y\n        self.train_prediction = self.model.fit_predict(df, roles = {'target':'target'}).data\n        return self\n    def predict_proba(self, X):\n        X = self.dataframe(X)\n        return self.model.predict(X).data\n\npipeline1 = make_pipeline(MyTransformer1(),my_model1)\npipeline2 = make_pipeline(MyTransformer2(),my_model2)\npipeline3 = make_pipeline(MyTransformer3(),my_model3)\npipeline4 = make_pipeline(MyTransformer4(),my_model4)\npipeline5 = make_pipeline(MyTransformer5(),my_model5)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:53:03.040792Z","iopub.execute_input":"2021-06-06T02:53:03.041086Z","iopub.status.idle":"2021-06-06T02:53:30.964897Z","shell.execute_reply.started":"2021-06-06T02:53:03.041059Z","shell.execute_reply":"2021-06-06T02:53:30.963772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_final_estimator = AutoMLClassifier()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:53:30.966546Z","iopub.execute_input":"2021-06-06T02:53:30.966955Z","iopub.status.idle":"2021-06-06T02:53:31.004685Z","shell.execute_reply.started":"2021-06-06T02:53:30.966911Z","shell.execute_reply":"2021-06-06T02:53:31.003767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier,StackingClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss,accuracy_score\n\nvoting_estimators = [\n    ('mod1', pipeline1),\n    ('mod2', pipeline2),\n    ('mod3', pipeline3),\n    ('mod4', pipeline4),\n    ('mod5', pipeline5),\n]\nstacking_estimators = [\n    ('mod1', pipeline1),\n    ('mod2', pipeline2),\n    ('mod3', pipeline3),\n    ('mod4', pipeline4),\n    ('mod5', pipeline5),\n]\n\nX = train[features]\ny = train['target']\n\nmod_vot = VotingClassifier(\n    estimators=voting_estimators,\n    voting = 'soft',\n).fit(X, y)\n\nmod_stk = StackingClassifier(\n    estimators=stacking_estimators,\n    final_estimator=my_final_estimator,\n    stack_method='predict_proba',\n    cv=20,\n).fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:53:31.006679Z","iopub.execute_input":"2021-06-06T02:53:31.006987Z","iopub.status.idle":"2021-06-06T02:53:51.508322Z","shell.execute_reply.started":"2021-06-06T02:53:31.006958Z","shell.execute_reply":"2021-06-06T02:53:51.505313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test  = (mod_vot.predict_proba(test[features]) + mod_stk.predict_proba(test[features])) / 2\nsubmission = test[['id']].copy()\nsubmission['Class_1'] = y_pred_test[:,0]\nsubmission['Class_2'] = y_pred_test[:,1]\nsubmission['Class_3'] = y_pred_test[:,2]\nsubmission['Class_4'] = y_pred_test[:,3]\nsubmission['Class_5'] = y_pred_test[:,4]\nsubmission['Class_6'] = y_pred_test[:,5]\nsubmission['Class_7'] = y_pred_test[:,6]\nsubmission['Class_8'] = y_pred_test[:,7]\nsubmission['Class_9'] = y_pred_test[:,8]\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:53:51.509666Z","iopub.status.idle":"2021-06-06T02:53:51.510086Z"},"trusted":true},"execution_count":null,"outputs":[]}]}